# MacOS 自動操作エージェント 開発プラン (plan.md)

## 1. プロジェクト概要
ユーザーの自然言語による指示を受け取り、MacOS の GUI を直接操作してタスクを完了させる CLI エージェントを構築します。
PyAutoGUI による操作と、Vision LLM（GPT-4o / Claude 3.5 Sonnet）による画面認識を組み合わせた Agent Loop を実装します。

## 2. アーキテクチャ構成
本プロジェクトは **Bun (TypeScript)** をメインコントローラーとし、**Python (PyAutoGUI)** を低レイヤーの操作ツールとして利用するハイブリッド構成とします。

- **Main Controller (Bun/TS)**:
  - ユーザープロンプトの受付と対話。
  - LLM（Vision API）へのリクエストと推論。
  - Agent Loop の管理（状態遷移、終了判定）。
  - Python プロセスの起動とコマンド送出。
- **Action Executor (Python/PyAutoGUI)**:
  - マウス操作（移動、クリック、ドラッグ）。
  - キーボード操作（タイピング、ホットキー）。
  - 画面情報の取得（スクリーンショット）。

## 3. Agent Loop の設計
以下のステップを繰り返すループを実装します。

1. **Observe (観察)**: 現在の画面をスクリーンショットとして撮影。
2. **Thought (思考)**: ゴール、過去の履歴、現在の画面を LLM に渡し、次に行うべき行動を思考。
3. **Action (実行)**: LLM が決定した操作（Tool Use）を PyAutoGUI を通じて実行。
4. **Verify (確認)**: 実行後の画面を再度確認し、目標が達成されたか、または次のステップが必要かを判定。

## 4. 実装ツール群 (PyAutoGUI Wrapper)
以下の機能を Python 側で実装し、TS から呼び出し可能にします。

- `screenshot()`: 現在の画面を保存し、パスまたは Base64 を返す。
- `click(x, y, clicks, button)`: 指定座標をクリック。
- `type_text(text)`: 文字列を入力。
- `press_key(key)`: 特定のキー（Enter, Escape等）を押下。
- `hotkey(keys)`: `command+space` などの組み合わせ実行。
- `mouse_move(x, y)`: マウスカーソルの移動。
- `scroll(amount)`: 画面のスクロール。

## 5. Vision 戦略
- **座標変換**: スクリーンショットの解像度と、実際のディスプレイ解像度（Retina等）の差異を吸収するため、0〜1000 の正規化座標を LLM に扱わせ、実行時に実座標へ変換します。
- **SoM (Set-of-Mark)**: 必要に応じて、UI 要素を赤枠で囲み番号を振るなどの前処理を行い、LLM の認識精度を高めます（フェーズ2以降）。

## 6. 開発ロードマップ
1. **フェーズ 1: 環境構築**
   - Bun プロジェクトの初期化。
   - Python 仮想環境の構築と PyAutoGUI のインストール。
   - TS から Python を呼び出すブリッジの実装。
2. **フェーズ 2: Tool 実装**
   - スクリーンショットと基本操作ツールの実装。
3. **フェーズ 3: Agent Loop 実装**
   - LLM (GPT-4o/Claude) 連携モジュールの作成。
   - ループ構造の実装。
4. **フェーズ 4: テスト & 調整**
   - 「YouTubeで検索」などの具体例による動作検証。
   - セーフティ機能（緊急停止キー等）の実装。

## 7. 実行環境の注意点
- **アクセシビリティ権限**: MacOS の「システム設定 > プライバシーとセキュリティ > アクセシビリティ」にて、使用するターミナル（または Python/Bun）への許可が必要です。
- **Retina ディスプレイ**: 解像度のスケーリング（2倍等）に注意して座標計算を行う必要があります。

